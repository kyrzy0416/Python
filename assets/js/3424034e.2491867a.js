"use strict";(self.webpackChunkmine=self.webpackChunkmine||[]).push([[358],{1458:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>_,contentTitle:()=>i,default:()=>m,frontMatter:()=>r,metadata:()=>s,toc:()=>l});var o=t(4848),a=t(8453);const r={},i="\u81ea\u52a8\u5316\u8bc6\u522b\u6846\u67b6",s={id:"scripts/auto_ocr_framework",title:"\u81ea\u52a8\u5316\u8bc6\u522b\u6846\u67b6",description:"\u8fd9\u662f\u5728\u5e2e\u52a9\u6211\u7684\u597d\u670b\u53cb\u5b9e\u73b0 \u6296\u5e97\u81ea\u52a8\u53d1\u9001\u6d88\u606f \u7684\u65f6\u5019\u5b9e\u73b0\u7684\u4e00\u4e2a\u6846\u67b6\uff0c\u672c\u6765\u5f88\u7b80\u964b\uff0c\u7136\u540e\u88ab\u6211\u786c\u751f\u751f\u7684\u62ff\u6765\u505a\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u81ea\u52a8\u5316\u8bc6\u522b\u6846\u67b6\uff0c\u73b0\u5728\u624b\u6e38\u4e00\u5f00\u5237\u4e2a\u7259\u56de\u6765\u5c31\u5237\u5b8c\u4e86",source:"@site/docs/scripts/auto_ocr_framework.md",sourceDirName:"scripts",slug:"/scripts/auto_ocr_framework",permalink:"/Python-Basis-Notes/docs/scripts/auto_ocr_framework",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/scripts/auto_ocr_framework.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"\u811a\u672c\u96c6",permalink:"/Python-Basis-Notes/docs/category/\u811a\u672c\u96c6"},next:{title:"\u98de\u9e3d\u77e5\u8bc6\u5e93\u5bfc\u51fa",permalink:"/Python-Basis-Notes/docs/scripts/feige_export"}},_={},l=[{value:"\u6280\u672f\u6808",id:"\u6280\u672f\u6808",level:2},{value:"\u5e38\u7528\u7684\u51e0\u4e2a\u65b9\u6cd5",id:"\u5e38\u7528\u7684\u51e0\u4e2a\u65b9\u6cd5",level:2},{value:"\u5fc3\u7406\u6d4b\u8bd5\u81ea\u52a8\u5316\u903b\u8f91\uff08\u62db\u8058\u7528\uff09",id:"\u5fc3\u7406\u6d4b\u8bd5\u81ea\u52a8\u5316\u903b\u8f91\u62db\u8058\u7528",level:2},{value:"\u7269\u534e\u5f25\u65b0\u81ea\u52a8\u5316\u903b\u8f91",id:"\u7269\u534e\u5f25\u65b0\u81ea\u52a8\u5316\u903b\u8f91",level:2},{value:"\u6846\u67b6\u4ee3\u7801",id:"\u6846\u67b6\u4ee3\u7801",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.h1,{id:"\u81ea\u52a8\u5316\u8bc6\u522b\u6846\u67b6",children:"\u81ea\u52a8\u5316\u8bc6\u522b\u6846\u67b6"}),"\n",(0,o.jsxs)(e.p,{children:["\u8fd9\u662f\u5728\u5e2e\u52a9\u6211\u7684\u597d\u670b\u53cb\u5b9e\u73b0 ",(0,o.jsx)(e.code,{children:"\u6296\u5e97\u81ea\u52a8\u53d1\u9001\u6d88\u606f"})," \u7684\u65f6\u5019\u5b9e\u73b0\u7684\u4e00\u4e2a\u6846\u67b6\uff0c\u672c\u6765\u5f88\u7b80\u964b\uff0c\u7136\u540e\u88ab\u6211\u786c\u751f\u751f\u7684\u62ff\u6765\u505a\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u81ea\u52a8\u5316\u8bc6\u522b\u6846\u67b6\uff0c\u73b0\u5728\u624b\u6e38\u4e00\u5f00\u5237\u4e2a\u7259\u56de\u6765\u5c31\u5237\u5b8c\u4e86"]}),"\n",(0,o.jsx)(e.h2,{id:"\u6280\u672f\u6808",children:"\u6280\u672f\u6808"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"pandas"}),"\n",(0,o.jsx)(e.li,{children:"cv2"}),"\n",(0,o.jsx)(e.li,{children:"pyautogui"}),"\n",(0,o.jsx)(e.li,{children:"functools"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"\u5e38\u7528\u7684\u51e0\u4e2a\u65b9\u6cd5",children:"\u5e38\u7528\u7684\u51e0\u4e2a\u65b9\u6cd5"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:"click_image"})," \u70b9\u51fb\u56fe\u7247"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:"click_image_until_another_appears"})," \u70b9\u51fb\u56fe\u7247\u76f4\u5230\u4e0b\u4e00\u4e2a\u56fe\u7247\u51fa\u73b0"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:"click_image_sequence"})," \u70b9\u51fb\u4e00\u7cfb\u5217\u56fe\u7247\uff0c\u53ef\u4ee5\u4f20\u5165 List"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:"type_text"})," \u8f93\u5165\u6587\u5b57"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:"screenshot_and_click"})," OCR\u540e\u627e\u5230\u6307\u5b9a\u6587\u5b57\u70b9\u51fb"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:"process_screenshot_for_ocr"})," OCR\u56fe\u7247\u5f97\u5230\u6570\u636e"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"\u5fc3\u7406\u6d4b\u8bd5\u81ea\u52a8\u5316\u903b\u8f91\u62db\u8058\u7528",children:"\u5fc3\u7406\u6d4b\u8bd5\u81ea\u52a8\u5316\u903b\u8f91\uff08\u62db\u8058\u7528\uff09"}),"\n",(0,o.jsx)(e.p,{children:"@todo \u4e3b\u8981\u662f\u6709\u56fe\u7247\uff0c\u6709\u65f6\u95f4\u5355\u72ec\u5f00\u4e00\u4e2a\u4ed3\u5e93\u516c\u5f00\u4ee3\u7801"}),"\n",(0,o.jsx)(e.h2,{id:"\u7269\u534e\u5f25\u65b0\u81ea\u52a8\u5316\u903b\u8f91",children:"\u7269\u534e\u5f25\u65b0\u81ea\u52a8\u5316\u903b\u8f91"}),"\n",(0,o.jsx)(e.p,{children:"@todo \u4e3b\u8981\u662f\u6709\u56fe\u7247\uff0c\u6709\u65f6\u95f4\u5355\u72ec\u5f00\u4e00\u4e2a\u4ed3\u5e93\u516c\u5f00\u4ee3\u7801"}),"\n",(0,o.jsx)(e.h2,{id:"\u6846\u67b6\u4ee3\u7801",children:"\u6846\u67b6\u4ee3\u7801"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import hashlib\nimport math\nimport pandas as pd\nimport pyperclip\nimport requests\nimport base64\nimport cv2\nimport pyautogui\nimport time\nimport random\nimport numpy as np\nimport logging\nfrom io import BytesIO\nfrom functools import wraps\nfrom functools import lru_cache\nfrom config import SCREENSHOT_REGION\n\nlogging.basicConfig(level=logging.INFO)\n\n\ndef retry_on_failure(retries=3, delay=1):\n    """\n    \u88c5\u9970\u5668\uff0c\u7528\u4e8e\u5728\u51fd\u6570\u5931\u8d25\u65f6\u91cd\u8bd5\n    :param retries: \u91cd\u8bd5\u6b21\u6570\n    :param delay: \u91cd\u8bd5\u95f4\u9694\u65f6\u95f4\n    """\n\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            for attempt in range(retries):\n                result = func(*args, **kwargs)\n                if result:\n                    return result\n                logging.warning(f"\u5c1d\u8bd5 {attempt + 1} \u5931\u8d25\uff0c\u6b63\u5728\u91cd\u8bd5...")\n                time.sleep(delay)\n            logging.error(f"\u6240\u6709 {retries} \u6b21\u5c1d\u8bd5\u5931\u8d25\u3002")\n            return None\n\n        return wrapper\n\n    return decorator\n\n\nclass AutomationTool:\n    # \u5b9a\u4e49\u5e38\u91cf\n    LEFT = \'left\'\n    RIGHT = \'right\'\n    FULL = \'full\'\n\n    # \u7f13\u5b58\u6700\u8fd1\u4e00\u6b21\u7684\u622a\u56fe\u548c OCR \u7ed3\u679c\n    _last_screenshot = None\n    _last_screenshot_time = 0\n    _last_screenshot_hash = None\n    _last_ocr_result = None\n    _screenshot_cache_duration = 1  # \u7f13\u5b58\u6301\u7eed\u65f6\u95f4\uff08\u79d2\uff09\n\n    UMI_OCR_URL = "http://127.0.0.1:1224/api/ocr"\n\n    @staticmethod\n    @lru_cache(maxsize=None)\n    def read_excel(excel_path, usecols="A") -> pd.DataFrame:\n        """\n        \u8bfb\u53d6Excel\u6587\u4ef6\u4e2d\u6307\u5b9a\u7684\u5217\u6570\u636e\n        :param excel_path: Excel\u6587\u4ef6\u8def\u5f84\n        :param usecols: \u8981\u8bfb\u53d6\u7684\u5217\uff08\u9ed8\u8ba4\u8bfb\u53d6\u7b2cA\u5217\uff09\n        :return: \u5305\u542b\u6307\u5b9a\u5217\u6570\u636e\u7684DataFrame\n        """\n        df = pd.read_excel(excel_path, usecols=usecols)\n        return df\n\n    @staticmethod\n    def ocr_image(base64_image_data):\n        """\n        \u53d1\u9001HTTP\u8bf7\u6c42\u5230Umi-OCR\n        :param base64_image_data:\n        :return:\n        """\n        try:\n            response = requests.post(AutomationTool.UMI_OCR_URL, json={ "base64": base64_image_data })\n            response.raise_for_status()\n            return response.json()\n        except requests.RequestException as e:\n            logging.error(f"OCR\u8bf7\u6c42\u5931\u8d25: {e}")\n            return None\n\n    @staticmethod\n    def capture_screenshot():\n        """\n        \u622a\u53d6\u5c4f\u5e55\u5e76\u8fd4\u56dePIL\u683c\u5f0f\u7684\u56fe\u50cf\n        :return:\n        """\n        # \u5982\u679cSCREENSHOT_REGION\u4e3a\u7a7a\n        region = SCREENSHOT_REGION if SCREENSHOT_REGION else AutomationTool.FULL\n        # \u5224\u65adSCREENSHOT_REGION\uff08\u622a\u56fe\u662f\u5de6\u534a\u90e8\u5206\u8fd8\u662f\u5168\u5c4f\u5e55\uff09\n        if region == AutomationTool.LEFT:\n            logging.info("\u622a\u53d6\u5c4f\u5e55\u7684\u5de6\u534a\u90e8\u5206")\n            return AutomationTool.capture_screenshot_half(AutomationTool.LEFT)\n        elif region == AutomationTool.RIGHT:\n            logging.info("\u622a\u53d6\u5c4f\u5e55\u7684\u53f3\u534a\u90e8\u5206")\n            return AutomationTool.capture_screenshot_half(AutomationTool.RIGHT)\n        elif region == AutomationTool.FULL:\n            logging.info("\u622a\u53d6\u6574\u4e2a\u5c4f\u5e55")\n            return pyautogui.screenshot()\n        else:\n            raise ValueError("\u622a\u56fe\u533a\u57df\u65e0\u6548\u3002\u8bf7\u4f7f\u7528\'left\'\u3001\'right\'\u6216\'full\'")\n\n    @staticmethod\n    def capture_screenshot_half(side=LEFT):\n        """\n        \u622a\u53d6\u5c4f\u5e55\u7684\u5de6\u534a\u90e8\u5206\u6216\u53f3\u534a\u90e8\u5206\n        :param side: \'left\' \u6216 \'right\'\uff0c\u9ed8\u8ba4\u4e3a \'left\'\n        :return: \u622a\u53d6\u7684\u56fe\u50cf\n        """\n        # \u83b7\u53d6\u5c4f\u5e55\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\n        screen_width, screen_height = pyautogui.size()\n        # \u622a\u53d6\u6574\u4e2a\u5c4f\u5e55\n        screenshot = pyautogui.screenshot()\n        # \u8ba1\u7b97\u5bbd\u5ea6\u7684 73%\n        width_73_percent = int(screen_width * 0.73)\n        \n        if side == AutomationTool.LEFT:\n            # \u88c1\u526a\u51fa\u5de6\u534a\u90e8\u5206\n            half = screenshot.crop((0, 0, width_73_percent, screen_height))\n        elif side == AutomationTool.RIGHT:\n            # \u88c1\u526a\u51fa\u53f3\u534a\u90e8\u5206\n            half = screenshot.crop((screen_width - width_73_percent, 0, screen_width, screen_height))\n        else:\n            raise ValueError("\u65e0\u6548\u7684side\u53c2\u6570\u3002\u8bf7\u4f7f\u7528\'left\'\u6216\'right\'")\n        \n        # half.save(f"{side}_region.png") # \u8c03\u8bd5\u4f7f\u7528\n        return half\n\n    @staticmethod\n    def convert_image_to_base64(pil_image) -> str:\n        """\n        \u5c06PIL\u683c\u5f0f\u56fe\u50cf\u8f6c\u6362\u4e3aBase64\u7f16\u7801\n        :param pil_image:\n        :return:\n        """\n        buffered = BytesIO()\n        pil_image.save(buffered, format="PNG")\n        img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")\n        return img_base64\n\n    @staticmethod\n    def convert_image_to_opencv(pil_image):\n        """\n        \u5c06PIL\u683c\u5f0f\u56fe\u50cf\u8f6c\u6362\u4e3aOpenCV\u683c\u5f0f\n        :param pil_image:\n        :return:\n        """\n        np_image = np.array(pil_image)\n        return cv2.cvtColor(np_image, cv2.COLOR_RGB2BGR)\n\n    @staticmethod\n    def extract_text_in_box(ocr_data, x1, y1, x2, y2):\n        """\n        \u63d0\u53d6\u7ed9\u5b9a\u5750\u6807\u6846\u5185\u7684\u6587\u5b57\u3002\n        :param ocr_data: OCR \u7ed3\u679c\u6570\u636e\n        :param x1, y1, x2, y2: \u6307\u5b9a\u7684\u5750\u6807\u6846 (\u5de6\u4e0a\u89d2 x1, y1 \u548c \u53f3\u4e0b\u89d2 x2, y2)\n        :return: \u8bc6\u522b\u5230\u7684\u6587\u5b57\n        """\n        for item in ocr_data[\'data\']:\n            box = item[\'box\']\n            text = item[\'text\']\n            x_min = min([point[0] for point in box])\n            y_min = min([point[1] for point in box])\n            x_max = max([point[0] for point in box])\n            y_max = max([point[1] for point in box])\n            # \u5224\u65ad box \u662f\u5426\u5728\u6307\u5b9a\u8303\u56f4\u5185\n            if x_min >= x1 and y_min >= y1 and x_max <= x2 and y_max <= y2:\n                return text\n        return None\n\n    @staticmethod\n    def click_on_text(ocr_data, target_text):\n        """\n        \u6839\u636e\u8bc6\u522b\u5230\u7684\u6587\u5b57\uff0c\u79fb\u52a8\u9f20\u6807\u5e76\u70b9\u51fb\u76ee\u6807\u6587\u5b57\u7684\u4f4d\u7f6e\n        :param ocr_data:\n        :param target_text:\n        :return:\n        """\n        for item in ocr_data[\'data\']:\n            text = item[\'text\']\n            if target_text in text:\n                box = item[\'box\']\n                x_min = min([point[0] for point in box])\n                y_min = min([point[1] for point in box])\n                x_max = max([point[0] for point in box])\n                y_max = max([point[1] for point in box])\n                # \u8ba1\u7b97\u4e2d\u5fc3\u4f4d\u7f6e\u5e76\u6dfb\u52a0\u968f\u673a\u504f\u79fb\n                center_x = (x_min + x_max) // 2 + AutomationTool.human_like_offset()\n                center_y = (y_min + y_max) // 2 + AutomationTool.human_like_offset()\n                # \u83b7\u53d6\u5f53\u524d\u9f20\u6807\u4f4d\u7f6e\n                current_x, current_y = pyautogui.position()\n                # \u6a21\u62df\u4eba\u7c7b\u9f20\u6807\u79fb\u52a8\n                AutomationTool.move_mouse_smoothly((current_x, current_y), (center_x, center_y))\n                # \u7b49\u5f85\u968f\u673a\u65f6\u95f4\n                time.sleep(AutomationTool.human_like_delay())\n                # \u70b9\u51fb\n                pyautogui.click()\n                logging.info(f"\u70b9\u51fb\u4e86\u6587\u5b57: {text}, \u4f4d\u7f6e: {center_x}, {center_y}")\n                return True\n        logging.warning(f"\u672a\u627e\u5230\u76ee\u6807\u6587\u5b57: {target_text}")\n        return False\n\n    @staticmethod\n    def type_text(input_text):\n        """\n        \u50cf\u7c98\u8d34\u4e00\u6837\u5728\u5f53\u524d\u7126\u70b9\u8f93\u5165\u6846\u4e2d\u5feb\u901f\u8f93\u5165\u6307\u5b9a\u6587\u5b57\n        :param input_text:\n        :return:\n        """\n        try:\n            # \u5c06\u6587\u672c\u590d\u5236\u5230\u526a\u8d34\u677f\n            pyperclip.copy(str(input_text))\n            # \u6a21\u62df Ctrl + V \u7c98\u8d34\uff08Windows/Linux\uff09\uff0c\u6216\u8005 Command + V\uff08macOS\uff09\n            pyautogui.hotkey(\'ctrl\', \'v\')\n        except Exception as e:\n            logging.error(f"\u8f93\u5165\u6587\u5b57\u5931\u8d25: {e}")\n\n    @staticmethod\n    @retry_on_failure(retries=3, delay=1)\n    def screenshot_and_click(target_text):\n        """\n        \u622a\u56fe\u5e76\u70b9\u51fb\u6307\u5b9a\u6587\u5b57\n        :param target_text:\n        :return:\n        """\n        ocr_data = AutomationTool.process_screenshot_for_ocr()\n        if ocr_data:\n            # \u6839\u636e\u76ee\u6807\u6587\u5b57\u8fdb\u884c\u70b9\u51fb\n            clicked = AutomationTool.click_on_text(ocr_data, target_text)\n            if clicked:\n                time.sleep(1)\n            logging.info(f"\u6210\u529f\u70b9\u51fb\u76ee\u6807\u6587\u5b57: {target_text}")\n            return True\n        else:\n            logging.warning(f"\u672a\u627e\u5230\u76ee\u6807\u6587\u5b57: {target_text}")\n            return False\n\n    @staticmethod\n    def find_text_in_screen(target_text: str) -> bool:\n        """\n        \u622a\u56fe\u5e76\u5224\u65ad\u662f\u5426\u5b58\u5728\u67d0\u4e2a\u6587\u5b57\n        :param target_text:\n        :return:\n        """\n        ocr_data = AutomationTool.process_screenshot_for_ocr()\n        if ocr_data:\n            # \u904d\u5386\u6240\u6709\u8bc6\u522b\u5230\u7684\u6587\u5b57\uff0c\u5224\u65ad\u662f\u5426\u5df2\u7ecf\u5305\u542b\u4e86\u53d1\u9001\u7684\u6d88\u606f\n            for item in ocr_data[\'data\']:\n                if target_text in item[\'text\']:\n                    logging.info(f"\u627e\u5230\u76f8\u5e94\u76ee\u6807\u6587\u5b57\uff1a{target_text}")\n                    return True\n        logging.warning(f"\u672a\u627e\u5230\u76f8\u5e94\u76ee\u6807\u6587\u5b57\uff1a{target_text}")\n        return False\n\n    @staticmethod\n    def find_image_in_screenshot(template_path, threshold=0.8):\n        """\n        \u5728\u5c4f\u5e55\u622a\u56fe\u4e2d\u67e5\u627e\u7ed9\u5b9a\u56fe\u7247\u6a21\u677f\uff08\u4f7f\u7528\u7070\u5ea6\u56fe\uff09\n        :param template_path:\n        :param threshold: \u5339\u914d\u9608\u503c\n        :return:\n        """\n        screenshot = AutomationTool.capture_screenshot()\n        screenshot_cv = AutomationTool.convert_image_to_opencv(screenshot)\n        # \u8f6c\u6362\u4e3a\u7070\u5ea6\u56fe\n        screenshot_gray = cv2.cvtColor(screenshot_cv, cv2.COLOR_BGR2GRAY)\n        # \u8bfb\u53d6\u6a21\u677f\u56fe\u7247\u5e76\u8f6c\u6362\u4e3a\u7070\u5ea6\u56fe\n        template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n        if template is None:\n            logging.error(f"\u65e0\u6cd5\u8bfb\u53d6\u6a21\u677f\u56fe\u7247\uff1a{template_path}")\n            return None\n        # \u83b7\u53d6\u6a21\u677f\u7684\u5bbd\u9ad8\n        h, w = template.shape[:2]\n        # \u4f7f\u7528\u6a21\u677f\u5339\u914d\u67e5\u627e\u6a21\u677f\n        res = cv2.matchTemplate(screenshot_gray, template, cv2.TM_CCOEFF_NORMED)\n        # \u83b7\u53d6\u6700\u4f73\u5339\u914d\u4f4d\u7f6e\n        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n        if max_val > threshold:\n            top_left = max_loc\n            center_x = top_left[0] + w // 2\n            center_y = top_left[1] + h // 2\n            return center_x, center_y\n        else:\n            logging.info("\u672a\u627e\u5230\u5339\u914d\u7684\u56fe\u7247")\n            return None\n\n    @staticmethod\n    @retry_on_failure(retries=3, delay=2)\n    def click_image(template_path):\n        """\n        \u5728\u5c4f\u5e55\u4e0a\u67e5\u627e\u56fe\u7247\u5e76\u70b9\u51fb\n        :param template_path:\n        :return:\n        """\n        position = AutomationTool.find_image_in_screenshot(template_path)\n        logging.info(f"\u56fe\u7247\u4f4d\u7f6e: {position}")\n        if position:\n            # \u83b7\u53d6\u5f53\u524d\u9f20\u6807\u4f4d\u7f6e\n            current_x, current_y = pyautogui.position()\n            # \u79fb\u52a8\u9f20\u6807\u5230\u76ee\u6807\u4f4d\u7f6e\n            AutomationTool.move_mouse_smoothly((current_x, current_y), position, duration=0.3)\n            # \u7b49\u5f85\u968f\u673a\u65f6\u95f4\n            time.sleep(AutomationTool.human_like_delay())\n            # \u70b9\u51fb\n            pyautogui.click()\n            logging.info(f"\u70b9\u51fb\u4e86\u56fe\u7247\u4f4d\u7f6e: {position}")\n            return True\n        else:\n            logging.warning(f"\u672a\u627e\u5230\u56fe\u7247: {template_path}")\n            return False\n    \n    @staticmethod\n    def click_image_until_another_appears(click_image_path, stop_image_path, max_attempts=10, delay_between_clicks=1):\n        """\n        \u6301\u7eed\u70b9\u51fb\u4e00\u4e2a\u56fe\u7247\uff0c\u76f4\u5230\u53e6\u4e00\u4e2a\u56fe\u7247\u51fa\u73b0\u4e3a\u6b62\u3002\n\n        :param click_image_path: \u8981\u70b9\u51fb\u7684\u56fe\u7247\u8def\u5f84\n        :param stop_image_path: \u51fa\u73b0\u540e\u505c\u6b62\u70b9\u51fb\u7684\u56fe\u7247\u8def\u5f84\n        :param max_attempts: \u6700\u5927\u5c1d\u8bd5\u6b21\u6570\n        :param delay_between_clicks: \u6bcf\u6b21\u70b9\u51fb\u4e4b\u95f4\u7684\u5ef6\u8fdf\uff08\u79d2\uff09\n        :return: \u5982\u679c\u6210\u529f\u627e\u5230\u505c\u6b62\u56fe\u7247\u8fd4\u56deTrue\uff0c\u5426\u5219\u8fd4\u56deFalse\n        """\n        for attempt in range(max_attempts):\n            # \u68c0\u67e5\u505c\u6b62\u56fe\u7247\u662f\u5426\u51fa\u73b0\n            if AutomationTool.find_image_in_screenshot(stop_image_path):\n                logging.info(f"\u627e\u5230\u505c\u6b62\u56fe\u7247: {stop_image_path}")\n                return True\n\n            # \u70b9\u51fb\u6307\u5b9a\u56fe\u7247\n            AutomationTool.click_image(click_image_path)\n            logging.info(f"\u70b9\u51fb\u56fe\u7247: {click_image_path}\uff0c\u5c1d\u8bd5\u6b21\u6570: {attempt + 1}")\n\n            # \u7b49\u5f85\u6307\u5b9a\u65f6\u95f4\n            time.sleep(delay_between_clicks)\n\n        logging.warning(f"\u8fbe\u5230\u6700\u5927\u5c1d\u8bd5\u6b21\u6570 {max_attempts}\uff0c\u672a\u627e\u5230\u505c\u6b62\u56fe\u7247: {stop_image_path}")\n        return False\n\n    @staticmethod\n    def process_screenshot_for_ocr():\n        """\n        \u622a\u53d6\u5c4f\u5e55\u5e76\u8fdb\u884c OCR \u5904\u7406\uff0c\u4f7f\u7528\u7f13\u5b58\u4f18\u5316\n        :return: OCR \u6570\u636e\n        """\n        current_time = time.time()\n        # \u68c0\u67e5\u7f13\u5b58\u662f\u5426\u6709\u6548\n        if AutomationTool._last_screenshot is not None:\n            if current_time - AutomationTool._last_screenshot_time < AutomationTool._screenshot_cache_duration:\n                logging.info("\u4f7f\u7528\u7f13\u5b58\u7684 OCR \u7ed3\u679c")\n                return AutomationTool._last_ocr_result\n\n        # \u622a\u53d6\u5c4f\u5e55\n        image = AutomationTool.capture_screenshot()\n        # \u8ba1\u7b97\u622a\u56fe\u7684\u54c8\u5e0c\u503c\n        image_hash = AutomationTool._calculate_image_hash(image)\n\n        # \u5982\u679c\u622a\u56fe\u5185\u5bb9\u672a\u53d8\u5316\uff0c\u76f4\u63a5\u8fd4\u56de\u7f13\u5b58\u7684 OCR \u7ed3\u679c\n        if AutomationTool._last_screenshot_hash == image_hash:\n            logging.info("\u622a\u56fe\u5185\u5bb9\u672a\u53d8\u5316\uff0c\u4f7f\u7528\u7f13\u5b58\u7684 OCR \u7ed3\u679c")\n            AutomationTool._last_screenshot_time = current_time\n            return AutomationTool._last_ocr_result\n\n        # \u66f4\u65b0\u7f13\u5b58\n        AutomationTool._last_screenshot = image\n        AutomationTool._last_screenshot_hash = image_hash\n        AutomationTool._last_screenshot_time = current_time\n\n        # \u8fdb\u884c OCR \u8bc6\u522b\n        image_base64 = AutomationTool.convert_image_to_base64(image)\n        ocr_result = AutomationTool.ocr_image(image_base64)\n\n        # \u7f13\u5b58 OCR \u7ed3\u679c\n        AutomationTool._last_ocr_result = ocr_result\n\n        return ocr_result\n\n    @staticmethod\n    def _calculate_image_hash(image):\n        """\n        \u8ba1\u7b97\u56fe\u50cf\u7684\u54c8\u5e0c\u503c\n        :param image: PIL \u56fe\u50cf\n        :return: \u54c8\u5e0c\u503c\u5b57\u7b26\u4e32\n        """\n        buffered = BytesIO()\n        image.save(buffered, format="PNG")\n        image_bytes = buffered.getvalue()\n        return hashlib.md5(image_bytes).hexdigest()\n\n    @staticmethod\n    def click_image_sequence(image_paths, delay_between=1, max_wait=10):\n        """\n        \u6309\u987a\u5e8f\u8bc6\u522b\u5e76\u70b9\u51fb\u4e00\u7cfb\u5217\u56fe\u7247\u3002\n        :param image_paths: \u56fe\u7247\u8def\u5f84\u5217\u8868\n        :param delay_between: \u6bcf\u6b21\u5c1d\u8bd5\u4e4b\u95f4\u7684\u5ef6\u8fdf\n        :param max_wait: \u7b49\u5f85\u7b2c\u4e8c\u5f20\u56fe\u7247\u51fa\u73b0\u7684\u6700\u5927\u65f6\u95f4\uff08\u79d2\uff09\n        :return: \u5982\u679c\u6210\u529f\u70b9\u51fb\u6240\u6709\u56fe\u7247\u8fd4\u56deTrue\uff0c\u5426\u5219\u8fd4\u56deFalse\n        """\n        for image_path in image_paths:\n            start_time = time.time()\n            while True:\n                if AutomationTool.click_image(image_path):\n                    break\n                if time.time() - start_time > max_wait:\n                    logging.warning(f"\u672a\u80fd\u5728\u89c4\u5b9a\u65f6\u95f4\u5185\u627e\u5230\u56fe\u7247: {image_path}")\n                    return False\n                time.sleep(delay_between)\n        logging.info("\u6210\u529f\u70b9\u51fb\u6240\u6709\u56fe\u7247")\n        return True\n\n    @staticmethod\n    def move_and_swipe_with_hold(image_path, swipe_distance=200, direction=\'right\', duration=0.5, button=\'left\'):\n        """\n        \u5c06\u9f20\u6807\u79fb\u52a8\u5230\u56fe\u7247\u7684\u4f4d\u7f6e\uff0c\u7136\u540e\u5411\u53f3\u6ed1\u52a8\u6307\u5b9a\u7684\u8ddd\u79bb\u3002\n\n        :param image_path: \u56fe\u7247\u7684\u4f4d\u7f6e\n        :param swipe_distance: \u5411\u53f3\u6ed1\u52a8\u7684\u8ddd\u79bb\uff08\u50cf\u7d20\uff09\n        :param direction: \u6ed1\u52a8\u7684\u65b9\u5411\uff0c\u53ef\u4ee5\u662f \'right\', \'left\', \'top\', \'bottom\'\n        :param duration: \u79fb\u52a8\u548c\u6ed1\u52a8\u7684\u6301\u7eed\u65f6\u95f4\uff08\u79d2\uff09,\n        :param button: \u6309\u4f4f\u7684\u9f20\u6807\u6309\u94ae\uff0c\u53ef\u4ee5\u662f \'left\', \'right\', \'middle\'\n        """\n        # \u79fb\u52a8\u5230\u76ee\u6807\u4f4d\u7f6e\n        position = AutomationTool.find_image_in_screenshot(image_path, 0.7)\n        if position is None:\n            logging.error(f"\u672a\u627e\u5230\u56fe\u7247\uff1a{image_path}")\n            return False\n        x, y = position\n\n        # \u83b7\u53d6\u5f53\u524d\u9f20\u6807\u4f4d\u7f6e\n        current_x, current_y = pyautogui.position()\n        # \u79fb\u52a8\u9f20\u6807\u5230\u56fe\u7247\u4f4d\u7f6e\n        AutomationTool.move_mouse_smoothly((current_x, current_y), (x, y), duration=0.3)\n\n        # \u7b49\u5f85\u4e00\u6bb5\u65f6\u95f4\uff0c\u786e\u4fdd\u9f20\u6807\u5df2\u7ecf\u79fb\u52a8\u5230\u76ee\u6807\u4f4d\u7f6e\n        time.sleep(AutomationTool.human_like_delay())\n\n        # \u6309\u4e0b\u9f20\u6807\u6309\u94ae\n        pyautogui.mouseDown(button=button)\n\n        # \u6839\u636e\u65b9\u5411\u53c2\u6570\u8ba1\u7b97\u76ee\u6807\u4f4d\u7f6e\n        if direction == \'right\':\n            target_x = x + swipe_distance\n            target_y = y\n        elif direction == \'left\':\n            target_x = x - swipe_distance\n            target_y = y\n        elif direction == \'top\':\n            target_x = x\n            target_y = y - swipe_distance\n        elif direction == \'bottom\':\n            target_x = x\n            target_y = y + swipe_distance\n        else:\n            raise ValueError("Invalid direction. Use \'right\', \'left\', \'top\', or \'bottom\'.")\n\n        # \u6309\u4f4f\u9f20\u6807\u5e76\u6ed1\u52a8\u5230\u76ee\u6807\u4f4d\u7f6e\n        AutomationTool.move_mouse_smoothly((x, y), (target_x, target_y), duration=duration, hold_button=button)\n        # \u7b49\u5f85\u968f\u673a\u65f6\u95f4\n        time.sleep(AutomationTool.human_like_delay())\n\n        logging.info(f"\u4ece\u4f4d\u7f6e ({x}, {y}) \u6ed1\u52a8\u5230 ({target_x}, {target_y})\uff0c\u65b9\u5411\uff1a{direction}")\n        return True\n\n    @staticmethod\n    def press_enter():\n        """\n        \u6309\u4e0b\u56de\u8f66\u952e\n        """\n        pyautogui.press(\'enter\')\n\n    @staticmethod\n    def press_esc():\n        """\n        \u6309\u4e0besc\u952e\n        """\n        pyautogui.press(\'esc\')\n\n    @staticmethod\n    def human_like_delay(min_delay=0.1, max_delay=0.3):\n        """\n        \u8fd4\u56de\u4e00\u4e2a\u4ecb\u4e8e min_delay \u548c max_delay \u4e4b\u95f4\u7684\u968f\u673a\u7b49\u5f85\u65f6\u95f4\n        """\n        return random.uniform(min_delay, max_delay)\n\n    @staticmethod\n    def human_like_offset(offset_range=2):\n        """\n        \u8fd4\u56de\u4e00\u4e2a\u5728 -offset_range \u5230 offset_range \u4e4b\u95f4\u7684\u968f\u673a\u504f\u79fb\n        """\n        return random.randint(-offset_range, offset_range)\n\n    @staticmethod\n    def move_mouse_smoothly(start_pos, end_pos, duration=0.5, hold_button=None):\n        """\n        \u6a21\u62df\u4eba\u7c7b\u7684\u9f20\u6807\u79fb\u52a8\uff0c\u4f7f\u7528 pyautogui \u7684 tween \u51fd\u6570\n        :param start_pos: \u8d77\u59cb\u4f4d\u7f6e (x, y)\n        :param end_pos: \u7ed3\u675f\u4f4d\u7f6e (x, y)\n        :param duration: \u603b\u6301\u7eed\u65f6\u95f4\uff08\u79d2\uff09\n        :param hold_button: \u5982\u679c\u9700\u8981\u5728\u79fb\u52a8\u8fc7\u7a0b\u4e2d\u6309\u4f4f\u9f20\u6807\u6309\u94ae\uff0c\u53ef\u4ee5\u6307\u5b9a \'left\', \'right\', \'middle\'\n        """\n        # \u6dfb\u52a0\u968f\u673a\u504f\u79fb\u5230\u7ed3\u675f\u4f4d\u7f6e\n        offset_x = AutomationTool.human_like_offset()\n        offset_y = AutomationTool.human_like_offset()\n        end_pos = (end_pos[0] + offset_x, end_pos[1] + offset_y)\n\n        # \u968f\u673a\u9009\u62e9\u4e00\u4e2a\u7f13\u52a8\u51fd\u6570\n        tween_funcs = [\n            pyautogui.easeInQuad,\n            pyautogui.easeOutQuad,\n            pyautogui.easeInOutQuad,\n            pyautogui.easeInBounce,\n            pyautogui.easeOutBounce,\n            pyautogui.easeInElastic,\n            pyautogui.easeOutElastic\n        ]\n        tween_func = random.choice(tween_funcs)\n\n        # \u6309\u4e0b\u9f20\u6807\u6309\u94ae\uff08\u5982\u679c\u9700\u8981\uff09\n        if hold_button:\n            pyautogui.mouseDown(button=hold_button)\n\n        # \u4f7f\u7528 pyautogui \u7684 moveTo \u51fd\u6570\uff0c\u6307\u5b9a\u6301\u7eed\u65f6\u95f4\u548c\u7f13\u52a8\u51fd\u6570\n        pyautogui.moveTo(end_pos[0], end_pos[1], duration=duration, tween=tween_func)\n\n        # \u91ca\u653e\u9f20\u6807\u6309\u94ae\uff08\u5982\u679c\u9700\u8981\uff09\n        if hold_button:\n            pyautogui.mouseUp(button=hold_button)\n\n    def custom_tween(x):\n        """\n        \u81ea\u5b9a\u4e49\u7f13\u52a8\u51fd\u6570\uff0c\u53ef\u4ee5\u8c03\u6574 x \u7684\u5e42\u6b21\u6765\u63a7\u5236\u901f\u5ea6\u66f2\u7ebf\n        """\n        return x ** 2  # \u6216\u8005\u5176\u4ed6\u6570\u5b66\u51fd\u6570\n\n    @staticmethod\n    def _bezier_curve(points, n=50):\n        """\n        \u751f\u6210\u8d1d\u585e\u5c14\u66f2\u7ebf\u7684\u70b9\u96c6\n        :param points: \u63a7\u5236\u70b9\u5217\u8868\n        :param n: \u70b9\u7684\u6570\u91cf\n        :return: \u70b9\u7684\u5217\u8868\n        """\n        result = []\n        for i in range(n + 1):\n            t = i / n\n            x = 0\n            y = 0\n            n_points = len(points)\n            for j, (px, py) in enumerate(points):\n                bernstein = AutomationTool._bernstein_poly(j, n_points - 1, t)\n                x += px * bernstein\n                y += py * bernstein\n            result.append((x, y))\n        return result\n\n    @staticmethod\n    def _bernstein_poly(i, n, t):\n        """\n        \u8ba1\u7b97\u4f2f\u6069\u65af\u5766\u591a\u9879\u5f0f\u503c\n        """\n        return math.comb(n, i) * (t ** i) * ((1 - t) ** (n - i))\n\n'})})]})}function m(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(c,{...n})}):c(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>i,x:()=>s});var o=t(6540);const a={},r=o.createContext(a);function i(n){const e=o.useContext(r);return o.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:i(n.components),o.createElement(r.Provider,{value:e},n.children)}}}]);